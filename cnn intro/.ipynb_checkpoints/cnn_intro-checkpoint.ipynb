{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b19723",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade tensorflow\n",
    "pip install opencv-python-headless"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f16002",
   "metadata": {},
   "source": [
    "# Resimlerin okunması, resim ve etiket dizilerinin oluşturulması aşaması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d385b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import csv\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42826c90",
   "metadata": {},
   "source": [
    "inputBasePath içerisinde her bir sınıf için o sınıf adıyla oluşturulmuş bir klasör vardır ve her klasör içerisinde o sınıfa ait resimler yer almaktadır. bu resimler her analiz adımında yeniden okunup işlenebilir ancak bu okuma sürecini yeniden yeniden yapmamak için resimler bir kereye mahsus okunup, istenirse yeniden boyutlandırılıp, istenirse filtre uygulanıp vs. daha sonra bir numpy array olarak kaydedilir. daha sonraki analiz işlemlerinden direkt bu array okunarak hızlıca işlem yapılabilir. oluştutulan array'ler outputBasePath yoluna kaydedilecek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb611ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputBasePath    = r\"C:\\Users\\ONUR\\Desktop\\corneal ulcer\\images\"\n",
    "outputBasePath =  r\"C:\\Users\\ONUR\\Desktop\\corneal ulcer\\imagearrays\" #bu klasörlerin daha önce oluşturulmuş olması gerek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d623a513",
   "metadata": {},
   "source": [
    "resimler yeniden boyutlandırılmak istenirse genişlik ve yükseklik değerleri burada tanımlanıyor.\n",
    "özellikle state-of-art modeller resimleri belli ölçülerde daha iyi işliyor. ideal değerleri öğrenip ona göre boyut verilebilir.\n",
    "\n",
    "Imagenet ile eğitilen VGG16, VGG19 ve ResNet modelleri 224×224 boyutunda,  Inception V3 ve Xception ise 299×299 boyutunda girdiye ihtiyaç duyar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9805946",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_width = 224\n",
    "image_height = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d46d2d",
   "metadata": {},
   "source": [
    "sınıf adlarını tutan bir dizi tanımlanıyor. bu sınıf adları aynı zamanda inputBasePath'te yer alan klasör isimleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26547dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['flaky_corneal_ulcers','point_flaky_mixed_corneal_ulcers','point_like_corneal_ulcers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00bf866",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(inputBasePath) #chdir -> change directory, inputBasePath yoluyla verilen dizine git\n",
    "\n",
    "X = [] # resimleri yani girdileri yani X değerlerini tutmak için dizi\n",
    "Y = [] # etiketleri yani Y değerlerini tutmak için dizi. her bir resmin etiketi içinde yer aldığı klasörün adı zaten\n",
    "\n",
    "i = 0\n",
    "for class1 in classes:\n",
    "  os.chdir(class1) #base yoldan sonra sıradaki sınıfı gösteren klasöre konumlan\n",
    "  print('=> '+class1) #o an üzerinde bulunulan sınıfı (klasör adını) yaz\n",
    "  for files in os.listdir('./'): # nokta mevcut dizini gösteriyor. ./ mevcut dizin altındakiler\n",
    "    img = cv2.imread(files) #dosya yolundan resmi binary array olarak okuma.resmi grayscale almak için ikinci parametreye 0 yazılır cv2.imread(files,0)\n",
    "    img = cv2.resize(img, (image_width,image_height)) #isteğe bağlı olarak resize edilebilir\n",
    "    X.append(img) #resmi oluşturan bit dizisini X'e ekle\n",
    "    Y.append(class1) # bu resmin sınıfı içinde bulunduğu klasör adı. resmin etiketi olarak bunu Y'ye ekle\n",
    "    i = i + 1\n",
    "  os.chdir('..') #bir üst dizine çık. bu sınıfla ve bunu içeren klasörler işimiz bitti\n",
    "  \n",
    "print(\"X : \",len(X))\n",
    "print(\"Y : \",len(Y))\n",
    "\n",
    "X = np.array(X).reshape(-1,image_width,image_height,3) #-1 ile verilen ilk değerin yerinde toplam resim adedi var; \n",
    "                #bu aynı kalacak. diğer parametreler verilen width ve height'e göre ve resmin renkli olduğunu \n",
    "                #belirten 3 ile yeniden şekillendirilecek\n",
    "Y = np.array(Y) #etiket adlarını içeren Y'yi reshape etmeye gerek yok. \n",
    "\n",
    "print(\"X : \",X.shape)\n",
    "print(\"Y : \",Y.shape)\n",
    "\n",
    "print(\"X : \",len(X))\n",
    "print(\"Y : \",len(Y))\n",
    "\n",
    "os.chdir('..') #bir üst dizine daha çıkıp sonra imagearrays klasörüne gidersek zaten outputBasePath'e ulaşmış olacağız\n",
    "os.chdir(\"imagearrays\")\n",
    "# üstteki iki satır yerine bunu direkt chdir(outputBasePath) olarak da yapabilirdik\n",
    "np.save(str(image_width)+'x'+str(image_height)+'_images', X) #diziyi kaydederken dosya adını en x boy_images olarak adlandır.\n",
    "                                                            #'224x224_images' gibi\n",
    "np.save(str(image_width)+'x'+str(image_height)+'_labels', Y) #diziyi kaydederken dosya adını en x boy_labels olarak adlandır.\n",
    "\n",
    "print(\"[ INFO - STAGE1 ]  NUMPY ARRAY CREATION COMPLETED \\n \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d8accc",
   "metadata": {},
   "source": [
    "# Sınıflandırma işlemleri\n",
    "Bu aşamadan sonra daha önce oluşturulan array'ler okunarak işlem yapılacak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3cd68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import MaxPool2D # üstteki MaxPooling2D ile aynı şey. ister onu ister bunu kullan. \n",
    "#kodda ikisi de kullanıldığı için eklendi. yoksa biri ile yapılsaydı da olurdu.\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff478396",
   "metadata": {},
   "source": [
    "data önce numpy array olarak kaydedilen görüntüleri (data) ve sınıf (label) etiketlerini oku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98225d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(r\"C:\\Users\\ONUR\\Desktop\\corneal ulcer\\imagearrays\\224x224_images.npy\")\n",
    "labels = np.load(r\"C:\\Users\\ONUR\\Desktop\\corneal ulcer\\imagearrays\\224x224_labels.npy\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672fe340",
   "metadata": {},
   "source": [
    "### Label Encoding\n",
    "\n",
    "array den okunan etiketler orjinal halde, string şeklinde. bunları 0 1 2 şeklinde kodlayacağız yani label encoding yapacağız"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35736637",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelEn = LabelEncoder() #string olan etiketleri 0 1 2 şeklinde kodla\n",
    "labels = labelEn.fit_transform(labels)\n",
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17000d54",
   "metadata": {},
   "source": [
    "### Train - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acadaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#veri array'e kaydedilmeden önce reshape edildiğinden array den okununca da düzgün gelir. yeniden reshape etmeye gerek yok\n",
    "#eğer array'e atarken son değer 3 olarak yazılmasaydı burada reshape gerekirdi\n",
    "\n",
    "#data =  data.reshape(-1,image_width , image_height , 3) \n",
    "                                                        \n",
    "\n",
    "\n",
    "\n",
    "# train -test split\n",
    "#%20 test %80 eğitim seti olacak şekilde böl\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size = .20, shuffle = True)\n",
    "\n",
    "\n",
    "print(\n",
    "\"\"\"\n",
    "x_train shape: {}\n",
    "x_test shape: {}\n",
    "y_train shape: {}\n",
    "y_test shape: {}\n",
    "\n",
    "\"\"\".format(x_train.shape, x_test.shape, y_train.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e65e70",
   "metadata": {},
   "source": [
    "# Normalizasyon (bu adım opsiyonel)\n",
    "Veriler normalize edilerek piksel değer aralıkları 0-1 aralığına çekilip daha hızlı işlem yapılması sağlanabilir.\n",
    "Normalizasyon işlem hızını arttırır ama her görüntü için başarı artışı getirmeyebilir, belki başarıyı düşürebilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d131a799",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_mean = np.mean(x_train)\n",
    "x_train_std = np.std(x_train)\n",
    "\n",
    "x_test_mean = np.mean(x_test)\n",
    "x_test_std = np.std(x_test)\n",
    "\n",
    "x_train = (x_train - x_train_mean)/x_train_std\n",
    "x_test = (x_test - x_test_mean)/x_test_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af7d7ab",
   "metadata": {},
   "source": [
    "### Train - Validation Split\n",
    "\n",
    "%20 test - %10 validation seti olacak şekilde ayır\n",
    "\n",
    "validation datası, modelin eğitimi esnasında train verisini doğrulamak için yani eğitim işlemi esnasındaki test sürecini gerçekleştirmek için kullanılıyor.\n",
    "x_test ve y_test ise eğitim süreci bittikten sonra eğitilen modeli daha önce hiç bilmediği verilerle test etmek için"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36831f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size = .10, shuffle = True,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07964b1a",
   "metadata": {},
   "source": [
    "### Model tanımlama\n",
    "kendimize göre bir model oluşturan ve bunu geri döndüren bir fonksiyon yazalım"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd666cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1(input_shape=(image_width ,image_height ,3), num_classes = 3): #parametrelerin varsayılan değerleri var. \n",
    "    #modelin giriş shape'i ve class sayısı= 3                                                                     \n",
    "    #burada oluşturulan model VGG16 mimarisi aslında. değiştirilebilir.\n",
    "\tmodel = Sequential()\n",
    "\tchanDim = -1\n",
    "\n",
    "\tmodel.add(Conv2D(64, (3,3), padding=\"same\",input_shape=input_shape))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(Conv2D(64, (3,3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\t# 2.Layer (CONV => RELU => CONV => RELU) * 2 => POOL\n",
    "\tmodel.add(Conv2D(128, (3,3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(Conv2D(128, (3,3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\t# 3.Layer (CONV => RELU => CONV => RELU) * 2 => POOL\n",
    "\tmodel.add(Conv2D(256, (3,3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(Conv2D(256, (3,3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(Conv2D(256, (3,3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\t# 4.Layer (CONV => RELU => CONV => RELU) * 2 => POOL\n",
    "\tmodel.add(Conv2D(512, (3,3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(Conv2D(512, (3,3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(Conv2D(512, (3,3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\t# 5.Layer (CONV => RELU => CONV => RELU) * 2 => POOL\n",
    "\tmodel.add(Conv2D(512, (3,3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(Conv2D(512, (3,3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(Conv2D(512, (3,3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\t# 1. TAM BAĞLANTI KATMANI => RELU KATMANI\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(4096))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\n",
    "\t# 2. TAM BAĞLANTI KATMANI => RELU KATMANI\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(4096))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\n",
    "\t# SOFTMAX\n",
    "\tmodel.add(Dense(num_classes))\n",
    "\tmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d94b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bir başka model\n",
    "def model2(input_shape=(image_width ,image_height ,3), num_classes = 3):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',padding = 'Same',input_shape=input_shape))\n",
    "    model.add(Conv2D(32,kernel_size=(3, 3), activation='relu',padding = 'Same',))\n",
    "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu',padding = 'Same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu',padding = 'Same'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.40))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax')) #ikili sınıflama olsaydı sigmoid kullanılırdı. \n",
    "                            #bu durumda zaten num_classes 1 olurdu. yani çıkış nöronu 1 tane olurdu.\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34583d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model2()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea4c5b9",
   "metadata": {},
   "source": [
    "#### Modeli görselleştirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e4ca11",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pydot #görselleştirme için gerekli kütüphane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e18cc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bb494e",
   "metadata": {},
   "source": [
    "#### Optimizer tanımla\n",
    "Eğitim işlemi sonucunda ağın bulduğu sonuç ile gerçekte olması gereken sonuç arasındaki fark ile oluşan hatayı loss function ile hesaplıyoruz. Loss fonksiyonu çoklu sınıflamalarda \"categorical_crossentropy\" , ikili sınıflamada \"binary_crossrntropy\" olarak seçiliyor. Loss hesaplandıktan sonra geriye yayılımla tüm parametrelerin optimize edilmesi gerekiyor. Bu aşamada kullanılan adım uzunluğu \"learning rate\" in (LR) duruma göre adaptif bir şekilde değiştirilmesi sonucu daha verimli kılar. \"Learning rate\" çok küçük olursa işlem uzun sürer, çok büyük olursa hatanın minimum değeri kaçırılabilir. Bu nedenle LR optimize edilmelidir. Bu iş için adaptif momentum optimizer yani \"adam\" optimizer kullanacağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a304bdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb51214f",
   "metadata": {},
   "source": [
    "#### LR anneaier tanımlama\n",
    "Optimizer'ın loss fonksiyonunun minimum noktasına daha hızlı ve etkin bir şekilde yakınsaması için LR'in tavlama (annealing) metodu kullanılır.\n",
    "LR loss fonksiyon çizgisi üzerindeki ilerleme adımlarıdır. LR büyük olursa daha hızlı ilerlenir ama örnekleme düşük olur ve optimizer lokal bir minimum noktaya takılıp kalabilir. Küçük olursa da işlem çok uzun sürer.\n",
    "Bu nedenle LR'nin training işlemi boyunca giderek azaltılıp loss fonksiyonunun minimum noktasına etkili bir şekilde ulaşılması sağlanır.\n",
    "Önce yüksek bir LR ile başlanıp daha sonra dinamik olarak her X adımda (epoch) eğer gerekli ise (accuracy artmıyorsa) LR azaltılır.\n",
    "Bu işlemi Keras.callbacks içindeki ReduceLROnPlateau fonksiyonu ile yapabiliriz. Diyelim ki eğer 3 epoch sonunda accuracy iyileşmezse LR'yi yarıya indirelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a879b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a learning rate annealer\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1,  factor=0.5, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be856e8b",
   "metadata": {},
   "source": [
    "#### modeli derle\n",
    "\n",
    "Loss fonksiyonu çoklu sınıflamalarda \"categorical_crossentropy\" , ikili sınıflamada \"binary_crossrntropy\" olarak seçilir.\n",
    "burada üç sınıf olduğu için categorical_crossentropy.\n",
    "çoklu sınıflamada modelin sonundaki sınıflayıcıda (flatten'den sonraki kısım) çıkışta sınıf sayısı kadar nöron olur.\n",
    "\n",
    "İkili sınıflama yapılıyorsa çıkış nöron sayısı tektir. bu tek çıkış 0 veya 1 olarak bir değer verir. bu durumda loss fonksiyonu binary_crossrntropy olur.\n",
    "\n",
    "DİKKAT: iki sınıfllı bir veri var/yok şeklinde ise ikili sınıflama uygundur. ama kırmızı-siyah, elma-çilek vs. gibi (yani kırmızı kırmızı değil şeklinde değil veya elma elma değil şeklinde yani var yok halinde değil) ve bu sınıflar 1, 2 gibi kodlanmışsa, çıkışta yine 2 nöron olur ve sınıflamada kategoriktir, binary değildir. bu durum aslında yapılan kurgu ile ilgili."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43d975b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1c5f98",
   "metadata": {},
   "source": [
    "##### epoch ve batch size tanımla\n",
    "\n",
    "epoch = model kaç iterasyon çalışacak\n",
    "batch size = resimler modele bit dizisi matrisleri olarak alınır. her bir adımda kaç resmin bit dizisi alınacak, yani kaç resim alınacak. bir seferde alınan resimler yığın (batch), yığındaki resim sayısı batch size\n",
    "\n",
    "cost fonksiyonu her bir batch için hesaplanır, buna göre geri yayılım yapılır. her bir resim için yapılsaydı süreç uzardı (belki hesap daha hassas olurdu). batch size azaldıkça daha ince hesap yapılır ama süreç uzar, batch size artarsa cost hesabı daha üstünkörü olur, başarı düşebilir. bu nedenle batch size optimum şekilde seçilmeli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a908c157",
   "metadata": {},
   "outputs": [],
   "source": [
    "epc = 5 \n",
    "bs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c1fd86",
   "metadata": {},
   "source": [
    "##### modeli çalıştır\n",
    "\n",
    "modeli fit edince çalışır. modelin her bir aşamasındaki sonuçlar history değişkenine raporlanır.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfe98ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train,y_train, batch_size=bs,\n",
    "                              epochs = epc, validation_data = (x_validate,y_validate),\n",
    "                              verbose = 1, callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053a560a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history nin içindeki history değerinin anahtarları raporu alınabilecek değerlerin adlarını gösterir\n",
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915d70af",
   "metadata": {},
   "source": [
    "#### Doğruluk grafiklerini çiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a5f869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29baaf60",
   "metadata": {},
   "source": [
    "#### Hata grafiklerini çiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd67645a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91447b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26601935",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y_pred hesaplanırken x_validate baz alınır ve Y_true da y_validate kabul edilirse modelin eğitimi sonucu oluşan matrise \n",
    "#ulaşılabilir. çünkü validation datası, modelin eğitimi esnasında train verisini doğrulamak için yani eğitim işlemi esnasındaki\n",
    "#test sürecini gerçekleştirmek için kullanılıyor.\n",
    "\n",
    "#x_test ve y_test ise eğitim süreci bittikten sonra eğitilen modeli daha önce hiç bilmediği verilerle test etmek için\n",
    "#bu verilere göre eğitilen modeli test edip confusion matrisi elde etmek istersek bu durumda\n",
    "#Y_pred için x_test'i baz alacağız, Y_true ise y_test olacak\n",
    "\n",
    "Y_pred = model.predict(x_validate)   #test süreci için Y_pred = model.predict(x_test)\n",
    "Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(y_validate,axis = 1)  #test süreci için Y_true = np.argmax(y_test,axis = 1)\n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes)\n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ba2250",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(Y_true, Y_pred_classes)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ca9b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a58a6e3",
   "metadata": {},
   "source": [
    "İstenirse eğitilen model daha sonra kullanılmak üzere, hesaplanan ağırlıkları ile kaydedilebilir. bunun için de bir yol tanımlaması yapabiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5b7217",
   "metadata": {},
   "outputs": [],
   "source": [
    "  os.chdir(r\"C:\\Users\\ONUR\\Desktop\\corneal ulcer\\models\") #modeli kaydetmek için \n",
    "  model.save('model1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4970f826",
   "metadata": {},
   "source": [
    "##### bir başka test işlemi ve confusion matrix çizimi\n",
    "bu kez test dataları kullanılarak hesap yapılıyor. confusion matrix üsttekinden stil olarak daha farklı çizdiirliyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5fc3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model(r\"C:\\Users\\ONUR\\Desktop\\corneal ulcer\\models\\model1.h5\")\n",
    "preds = model.predict(x_test)\n",
    "y_pred = np.zeros_like(preds)\n",
    "y_pred[np.arange(len(preds)), preds.argmax(1)] = 1\n",
    "classes = ['flaky_corneal_ulcers','point_flaky_mixed_corneal_ulcers','point_like_corneal_ulcers']\n",
    "confusionMatrix = np.zeros((len(classes),len(classes)))\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "\n",
    "  if np.array_equal(y_pred[i],y_test[i]):\n",
    "    index = np.argmax(y_test[i])\n",
    "    confusionMatrix[index,index] += 1\n",
    "\n",
    "  else:\n",
    "\n",
    "    index1 = np.argmax(y_test[i])\n",
    "    index2 = np.argmax(y_pred[i])\n",
    "    confusionMatrix[index1,index2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0760fcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy Score : \")\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "cm = accuracy_score(y_test, y_pred)\n",
    "sns.set(font_scale=0.8)\n",
    "sns.heatmap(confusionMatrix,annot=True, linewidths=1.0, cbar=False)\n",
    "print(\"--------------------------------------------------\")\n",
    "print(\"Confusion Matrix : \")\n",
    "print(confusionMatrix)\n",
    "print(\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c617d8",
   "metadata": {},
   "source": [
    "## Veri Arrtırımı (Data Augmentation)\n",
    "Bu işlem opsiyonel olarak yapılır.\n",
    "Daha iyi öğrenme ve overfitting probleminin önüne geçmek için elimizdeki mevcut verileri belirli biçimde dönüştürerek yeni yapay örnekler elde edip, elimizdeki örnekleri çeşitlendirebiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a307490",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ImageDataGenerator ile veri arttırım modelini kurgula ve datagen değikenine ata\n",
    "datagen = ImageDataGenerator(  \n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180) 10 degrees\n",
    "        zoom_range = 0.1, # Randomly zoom image %10\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width) %10\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height) %10\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False  # randomly flip images\n",
    "                        )\n",
    "datagen.fit(x_train) #datagen'i x_train üzerinden çalıştır ve veri üret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c9ca5a",
   "metadata": {},
   "source": [
    "##### Üretilen resimlerden görüntüle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a7a2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "for X_batch, y_batch in datagen.flow(x_train, y_train, batch_size=9):\n",
    "\t# create a grid of 3x3 images\n",
    "\tfor i in range(0, 9):\n",
    "\t\tpyplot.subplot(330 + 1 + i)\n",
    "\t\tpyplot.imshow(X_batch[i].reshape(224, 224,3))\n",
    "\t# show the plot\n",
    "\tpyplot.show()\n",
    "\tbreak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b763c4e",
   "metadata": {},
   "source": [
    "### Veri arttırımı ile birlikte modeli fit et\n",
    "Veri arttırımı uygulayarak modeli tekrar fit et ve sonuçları izle\n",
    "Bunun için fit_generator metodu kullanılır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcaabc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(datagen.flow(np.array(x_train),np.array(y_train), batch_size=bs), \n",
    "                              epochs = epc, validation_data = datagen.flow(np.array(x_validate),\n",
    "                             np.array(y_validate),batch_size=bs),verbose = 1, \n",
    "                              steps_per_epoch=x_train.shape[0] // bs, \n",
    "                              callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73beae7",
   "metadata": {},
   "source": [
    "Bu işlemin ardından model tekrar test edilebilir, sonuçlara, confusion matrix'e yukarıda yapılanların benzerleri ile ulaşılabilir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e661e0",
   "metadata": {},
   "source": [
    "### PRE_TRAINED MODEL UYGULAMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7feacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "base_model = VGG16(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False, \n",
    "    input_shape=(image_width ,image_height ,3)\n",
    "   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb545b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES=3\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "model.layers[0].trainable = False #ilk katmana eklenen vgg16 modelini tekrar  train etme, \n",
    "                                #imagenet'te train edilmiş ağırlıkları kullan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f62377",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee040f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b020381a",
   "metadata": {},
   "source": [
    "istersen data augmentation olmadan fit et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4fa294",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train,y_train, batch_size=bs,\n",
    "                              epochs = epc, validation_data = (x_validate,y_validate),\n",
    "                              verbose = 1, callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3e829b",
   "metadata": {},
   "source": [
    "istersen data augmentation kullanarak fit et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af61e339",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(datagen.flow(np.array(x_train),np.array(y_train), batch_size=bs), \n",
    "                              epochs = epc, validation_data = datagen.flow(np.array(x_validate),\n",
    "                             np.array(y_validate),batch_size=bs),verbose = 1, \n",
    "                              steps_per_epoch=x_train.shape[0] // bs, \n",
    "                              callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb759686",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
